1943 to 1956

- The seeds of modern AI were planted by classical philosophers who attempted to describe the process of human thinking as the "mechanical manipulation of symbols".
- "placing mind into matter"
- The physical symbol system hypothesis claims that both of these are also examples of physical symbol systems:
	- Intelligent human thought: the symbols are encoded in our brains. The expressions are thoughts. The processes are the mental operations of thinking.
	- A running artificial intelligence program: The symbols are data. The expressions are more data. The processes are programs that manipulate the data.

We are adding expressions, which is data. Symbols are also data. Then we run a process to manipulate and understand the data.

1951: First neural net machine, the SNARC

- Strong AI: "solved the venerable mind/body problem, explaining how a system composed of matter can have the properties of mind."
- Game AI would continue to be used as a measure of progress in AI throughout its history.
- 1956 conference learning mission: "every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it".
	- The birth of AI
	- At the conference Newell and Simon debuted the "Logic Theorist" and McCarthy persuaded the attendees to accept "Artificial Intelligence" as the name of the field.

1956–1974

During this time: 
	- Researchers expressed an intense optimism in private and in print, predicting that a fully intelligent machine would be built in less than 20 years.
	- Government agencies like ARPA poured money into the new field.
- Lots of excitement & optimisim. People thought we would solve the problem.

- Commonsense knowledge and reasoning
	- This requires that the program know most of the same things about the world that a child does.

McCarthy responded that what people do is irrelevant. He argued that what is really needed are machines that can solve problems—not machines that think as people do.

Gerald Sussman observed that "using precise language to describe essentially imprecise concepts doesn't make them any more precise."

"AI researchers were beginning to suspect—reluctantly, for it violated the scientific canon of parsimony—that intelligence might very well be based on the ability to use large amounts of diverse knowledge in different ways," writes Pamela McCorduck.

Moravec's paradox is the discovery by artificial intelligence and robotics researchers that, contrary to traditional assumptions, high-level reasoning requires very little computation, but low-level sensorimotor skills require enormous computational resources. The principle was articulated by Hans Moravec, Rodney Brooks, Marvin Minsky and others in the 1980s.

"The world is its own best model. It is always exactly up to date. It always has every detail there is to be known. The trick is to sense it appropriately and often enough." (Rodney Brooks)

Judea Pearl's highly influential 1988 book brought probability and decision theory into AI.

Among the many new tools in use were Bayesian networks, hidden Markov models, information theory, stochastic modeling and classical optimization. Precise mathematical descriptions were also developed for "computational intelligence" paradigms like neural networks and evolutionary algorithms.

It does not matter whether a machine is really thinking (as a person thinks) or is just acting like it is thinking.

Every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it.

If a machine acts as intelligently as human being, then it is as intelligent as a human being.